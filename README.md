# ğŸš€ Building LLM Playground

An interactive LLM playground to demystify how prompts, tokenization, and decoding work. Load GPT2, Qwen3, and inspect their internals in real-time. Master the foundations of effective LLM usage! ğŸ¤–âœ¨

---

## ğŸ“š Overview

This introductory project explores how **prompts**, **tokenization**, and **decoding settings** work in practice. It builds the foundation for effective use of large language models by loading models like **GPT2** and **Qwen3**, inspecting them, and running them hands-on.

---

## ğŸ¯ Learning Objectives

Upon completing this project, we would understand:

- ğŸ§© **Tokenization** - How raw text gets converted into discrete tokens
- ğŸ—ï¸ **GPT-2 and Transformer Architectures** - The basics of how modern LLMs work
- ğŸ¤— **Loading Pre-trained LLMs** - Using Hugging Face to access cutting-edge models
- ğŸ›ï¸ **Decoding Strategies** - Different approaches to generate text (greedy, sampling, beam search, etc.)
- ğŸ“ **Model Comparison** - Differences between completion and instruction-tuned models like Qwen3

---

## ğŸš€ Quick Start

### Step 1: Clone or Download the Project
Clone this repository or download it directly from GitHub and unzip the files:

```bash
git clone https://github.com/poonamjagwani/building-llm-playground.git
cd building-llm-playground
```

Alternatively, download the repository as a ZIP file from GitHub, then unzip it on your local machine.

### Step 2: Open in Your IDE
Open any preferred IDE:
- VS Code
- Cursor
- Antigravity
- Or any alternative!

### Step 3: Follow the Instructions
Open the notebook for the project and follow the below instructions on running it.

---

## ğŸ’» How to Run

Choose one of two options below:

### Option A: Google Colab (Recommended) â˜ï¸

**No local setup required!**

1. Upload the notebook to [Google Colab](https://colab.research.google.com)
2. Install dependencies if needed
3. Run cells in order

**Pros:** Free GPU access, no installation headaches

### Option B: Local Development with Conda ğŸ–¥ï¸

**For reproducibility and full control:**

1. Each project includes setup instructions
2. Install dependencies using:
   - **Conda:**
     ```bash
     conda env create -f environment.yaml
     conda activate llm-playground
     ```
   - **UV** (faster alternative):
     ```bash
     uv pip install -r requirements.txt
     ```

**Pros:** Full control, faster iteration, learn local development practices

---

## ğŸ“ Project Structure

```
building-llm-playground/
â”œâ”€â”€ llm-playground.ipynb        # Main notebook
â”œâ”€â”€ environment.yaml             # Conda environment
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ data/                        # Optional: datasets
â””â”€â”€ [supporting files]           # Optional: utilities, configs, etc.
```

### What's Inside:
- ğŸ“” **Primary notebook** (`llm-playground.ipynb`) - Interactive walkthrough with explanations
- ğŸ“¦ **Dependencies** (`environment.yaml` & `requirements.txt`) - All required packages
- ğŸ“‚ **Data folder** - Datasets and supporting files (if needed)
- ğŸ› ï¸ **Supporting files** - Utility scripts, config files, etc.

---

## ğŸ“‹ Prerequisites

- Python 3.8+
- Jupyter Notebook (for local development)
- GPU recommended but not required (Colab provides free GPU)
